# 宫颈细胞的检测论文阅读

## Abstract

 		本文提出了一种有效的子宫颈癌细胞/团块检测方法，称为比较检测器，以解决有限的数据问题。具体来说，我们利用最先进的基于提案的目标检测方法，以特征金字塔网络（FPN）的快速R-CNN作为基线，并通过与每个类别的原型表示进行比较来替代每个提案的分类。此外，我们建议从数据中学习背景类别的原型表示，而不是通过一些启发式来人工选择它们。

## 1、Introduction

​		为了缓解数据有限的问题,在本文中，我们提出了一种被称为比较检测器，它将图像分类[24–27]的一次/少量学习的比较思想迁移到基于cnn的目标检测中，用于宫颈细胞/肿块检测。具体来说，我们选择最先进的对象检测方法，Faster R-CNN[10]、FPN[11]作为基线模型和替换原始参数分类器，一种非参数的方案，基于将每个建议与每个类别的原型表示进行比较的思想，这些原型表示由参考图像生成。

​		由于缺乏直接用于宫颈细胞/团块检测的公共数据集，我们收集了一个小数据集Ds和一个中型数据集Df，并在其上评估了所提出的比较检测器的性能。当从小数据集d中学习模型时，我们的方法的性能明显优于基线模型，即比较检测器得到的mAP为26.3%，AR为35.7%，但基线模型只得到6.6%的mAP和12.9%的AR。当从中型数据集Df中学习模型时，我们的方法获得了48.8%的mAP，而基线只得到了45.2%的mAP，而在AR方面，我们的方法比基线提高了5.1%

​		我们总结了我们的贡献如下： 1)我们提出了一种称为比较检测器的端到端目标检测方法来处理宫颈细胞/团块检测中有限的数据问题；2)我们提出了一种直接学习背景原型表示的策略；3)我们的方法在中小型数据集上比基线表现得更好，并且在真正的自动辅助宫颈癌筛查系统中有潜在的应用前景。

## 2、相关工作

### 2.2 CNN-based object detection

### 2.3 few-shot learning 少样本学习

​		meta-learing 和learning-to-learn 策略是让机器学习模型学习如何学习的方法，它包括在许多相关的任务上训练一个学习算法（Meta-Learner），使它能够在只有少量样本的情况下，快速适应新的任务。元学习是一种元认知（Metacognition）的分支，它涉及到研究人们如何学习、知道、思考和工作，以便将这些知识应用到其他领域学习如何学习（Learning-to-Learn）是元学习的另一种说法，它强调了元学习的目标是提高学习者的学习能力和效率。

​		有三类：基于元、基于内存和基于优化

​		有限数据下的目标检测：大多数的目标检测工作都是用弱监督的方法，少部分是用少样本学习的方法。RepMet [50]引入了一种基于度量学习的子网络体系结构，在不使用外部数据的情况下学习训练类别的嵌入空间和分布。然而，RepMet涉及到外部类分布模块学习和网络参数更新之间的交替优化，而我们的解决方案是一个干净的、单步的训练框架。

## 3、比较检测器 Comparison detector

### 3.1 主要结构

​		比较检测器是基于区域建议检测结构，该结构由个用于特征提取的主干网络、一个用于生成区域建议的RPN和一个用于建议分类和边界框回归的头部组成。用比较分类器取代原始的参数分类器。选择FPN和Faster R-CNN作为基准模型。降低了模型复杂性，减少了小数据集的泛化问题。

​		比较器的主要结构分为了三个阶段。第一阶段，比较检测器通过FPN骨干[11]生成参考图像和整个图像的特征，没有任何额外的模型对参考图像进行编码。

> ,,比较检测器的整体结构。首先,n*K参考图像输入FPN骨干获得特征，然后输入生成原型表示块（Generating Prototype Representation Block GPRB）生成原型为每个类别表示，其中K是类别的数量不包括背景和n是每个类别的图像数量。同时，我们可以通过FPN和区域区域建议网络（RPN）从整个图像中获得区域建议的特征。应该注意的是，FPN主干网络是共享的。通过比较每个建议与所有原型表示的特征，我们可以得到该区域建议的类别。只有提案的建议被用来微调边界框。

![image-20230722220424869](D:/CODing/pics/image-20230722220424869.png)

​		第二阶段是从参考图像的金字塔特征中生成每个类别的原型，然后通过聚合函数Fk将它们聚合成类k的最终原型表示Fk，  预测的为Pm

> (a)从参考图像的金字塔特征中生成一个前景原型表示的过程。(b)从所有k类前景原型表示中学习背景原型表示。在这里，W；H和C分别是每个类别的原型表示的宽度、高度和通道

![image-20230722230338328](D:/CODing/pics/image-20230722230338328.png)

​		第三阶段是用于分类损失和位置回归的头部模型。由一些卷积层和全连接层组成。d(Fk,Pm)表示两者的距离。softmax函数是基于区域建议特征Pm和原型表示Fk的，其余的和Faster-RCNN with FPN一样。

位置损失和分类损失 

### 3.2 生成原型表示模块Generating prototype representation block(GPRB)

- 生成背景类别的原型表示

- 学习背景类别的原型表示

  ​		RPN产生了许多负面的提议，所以RCNN 增加了一个额外的背景类别来代表它们。在我们的比较检测器中，我们需要为每个类别选择n个参考图像，因此也需要选择背景类别的参考图像。然而，由于其压倒性的多样性，选择背景的参考图像是极其困难的

### 3.3 头部的分类和回归模块

### 3.4 选择参考图像的策略

​		我们从训练集中随机选择了每个类别的大约150个实例。这些实例的最短边大于16个像素。通过这种方式，我们从训练集中得到总共1,560个实例作为候选参考图像，从它们中我们可以在这些对象中选择合适的实例作为我们的参考图像。

​		有两种可能的方法。第一种方法是随机选择每个类别的几个实例作为参考图像。第二种方法是首先通过ImageNet预训练的模型[8]将所有1560个对象映射到特征空间中，得到每个对象的特征，然后使用t-SNE [53]进行特征降维（图4）。基于t-SNE的结果，我们通过经验得到了每个类别中的聚类数量。然后我们用它作为k均值的参数。最后，根据K-means的结果，选择最接近簇中心的实例作为参考图像。

## 4、实验结果和分析

ssh -p 18851 root@region-42.seetacloud.com

### 4.1 实验步骤

​		训练集 Df  6666张，测试集 744张， 并且从Df中选取762张图像建立一个小数据集Ds。

​		实验中用ResNet和FPN作为backbone,参数用ImageNet上预先训练的模型初始化。对于参考图像，我们重新调整为224x224大小，训练过程中 初始学习率为0.001 ，epoch=60, 小批量设为2，权重衰减和动量为0.0001和0.9。用mAP（平均像素精确度）、AR(平均召回率)作为评价指标

> 消融实验（Ablation Study）是一种研究方法，主要用于深度学习、机器学习和其他计算领域，用于理解一个模型的各个组成部分对其性能的影响。
>
> 在消融实验中，我们会移除模型的某些部分（例如，去掉某些特征、减少层的数目或更改优化算法等），然后观察这是否会影响模型的性能。通过这种方式，我们可以了解模型各个部分对最终性能的贡献，例如哪些特征对预测结果的影响最大，哪些可以被剔除而对模型性能影响不大。
>
> 举例来说，如果你正在使用一个具有多个深度学习特征的复杂模型，你可能会进行一系列的消融实验，例如移除某些特征或改变隐含层的数量，以了解这些特征和组件的相对重要性。
>
> 这种方法不仅能帮我们理解模型的行为、判断模型的健壮性，还能帮助我们优化模型，提升性能。但是，消融实验的结果可能受到随机性和模型初始化的影响，因此通常需要多次运行以得到可靠的结论。

### 4.2 主要实验过程 包括消融实验

![image-20230804104512017](D:/CODing/pics/image-20230804104512017.png)

​		通过消融实验，比较模型各个模块对模型准确率的影响。

​		实验表明 对背景的原型表示、特征金字塔 是有利于模型的性能

​		头部边界框回归和分类 ：共享模块比独立模块的性能要比模块好得多，实验表示边界框回归相比分类表现好，通过调整损失函数的权重系数$\lambda$=5来平衡分类损失和边界框位置损失。

​		三种评价指标：L2-distance、参数化的L2-distance、两者的拼接和平衡，最后得到第三种模型的性能最好，权重系数$\lambda$=5

​		![image-20230804231027353](D:/CODing/pics/image-20230804231027353.png)

​		小规模数据上比较检测器的性能明显好于基线模型，大规模数据上比较检测器的性能有提升

​		通过增加数据规模，发现比较检测器的性能和基线模型相比，提升不是很高

​		改进的比较检测器：我们还添加了一个线性分类器和边界盒回归，这与基线模型相同。最终的分类结果是比较分类器和线性分类器的加权平均值如下![image-20230804233700780](D:/CODing/pics/image-20230804233700780.png)

比较分类器和线性分类器损失函数

![image-20230804233801225](D:/CODing/pics/image-20230804233801225.png)

beta=0.5时，性能最好

### 4.3 

  比较检测器用了最新的Faster-R-CNN with FPN,不过在头部替换了比较分类器，此外还和先进的RetinaNet进行了比较，准确率还是比较检测器好。但是推理过程中，头部参数较多，推理地慢一点

## 5、总结

- 为了处理有限的训练数据集，我们基于与每个类别的参考图像进行比较，开发了比较分类器，可以作为基于建议的对象检测器的插件模块。
- 不用手动标注背景，而是从数据中去学习
- 设计了不同的模块和头部模型
- 实验结果表明，与基线值相比，我们的方法在小型数据集训练后的mAP提高了19.7%，AR提高了22.8%，在模型中结合线性分类器和比较分类器后，我们的方法在中等训练数据集上训练时，mAP提高了3.6%，AR提高了5.1%。
- 需要注意的是，我们的方法直接作用于整个图像，而不是基于原子核提取的斑块，因此每幅图像只需要进行一次前向传播，这使得推理非常有效。此外，所提出的方法可以灵活地集成到其他基于建议的方法中。