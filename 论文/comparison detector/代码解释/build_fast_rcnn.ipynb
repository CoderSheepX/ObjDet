{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9af2eda",
   "metadata": {},
   "source": [
    "# 搭建Fast-RCNN检测网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b419822e",
   "metadata": {},
   "source": [
    "设置好参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b77494",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ROI_SIZE = 7   #ROI（Region of Interest）7×7 大小是指在 RoI Pooling 或 RoI Align 层中，\n",
    "                    #对提取的特征图上的每个候选区域进行划分的固定尺寸\n",
    "    FAST_RCNN_NMS_IOU_THRESHOLD = 0.3 #表示进行非极大值抑制 (NMS) 时，用于确定是否合并边界框的 IoU 阈值。\n",
    "    FINAL_SCORE_THRESHOLD = 0.7  #表示在 Fast R-CNN 阶段，用于筛选预测边界框的得分阈值。得分低于该阈值的边界框将被丢弃。\n",
    "    FAST_RCNN_IOU_POSITIVE_THRESHOLD = 0.5  #判断一个 proposal 是否为正样本的 IoU 阈值\n",
    "    FAST_RCNN_MINIBATCH_SIZE = 200  #Fast R-CNN 阶段中用于训练的每个 mini-batch 的大小。\n",
    "    FAST_RCNN_POSITIVE_RATE = 0.33  #Fast R-CNN 阶段中正样本的比例。该比例控制 mini-batch 中正样本与负样本的数量比例。\n",
    "    DETECTION_MAX_INSTANCES = 200  #在生成最终检测结果时，每张图片允许的最大检测实例数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06a8614",
   "metadata": {},
   "source": [
    "## 初始化传入Fast-RCNN的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7005aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastRCNN(object):\n",
    "    def __init__(self,\n",
    "                 feature_pyramid,  #传入的金字塔特征\n",
    "                 rpn_proposals_boxes,#rpn产生的区域建议\n",
    "                 gtboxes_and_label,  # [batch_size, M, 5]\n",
    "                 #M表示真实目标的个数、5表示四个坐标加上类别\n",
    "                 origin_image,     #原始图像\n",
    "                 reference_feature,  #参考图像的特征 用于计算特征\n",
    "                 config,        #配置文件\n",
    "                 is_training,\n",
    "                 image_window):\n",
    "\n",
    "        self.feature_pyramid = feature_pyramid\n",
    "        self.rpn_proposals_boxes = rpn_proposals_boxes  # [batch_size, N, 4]\n",
    "        self.gtboxes_and_label = gtboxes_and_label\n",
    "        self.origin_image = origin_image\n",
    "        self.reference_feature = reference_feature\n",
    "        self.config = config\n",
    "        self.IS_TRAINING = is_training\n",
    "        self.window = image_window\n",
    "        self.level = config.LEVEL    #特征金字塔的层级\n",
    "        self.min_level = int(self.level[0][1])  #获得最小层级的编号\n",
    "        self.max_level = min(int(self.level[-1][1]), 5)  #获得最大层级的编号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a303cd90",
   "metadata": {},
   "source": [
    " 将输入的张量列表进行重塑，以合并批次维度和框维度，并返回一个新的张量列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa3c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def merge_batch_and_bboxes_dims(self, inputs):\n",
    "        \"\"\"\n",
    "        :param inputs:list of tensor\n",
    "        :return: list of tensor\n",
    "        \"\"\"\n",
    "        outputs = []\n",
    "        for input in inputs:\n",
    "            input_shape = input.get_shape().as_list()\n",
    "            output =tf.reshape(input, [-1,] + input_shape[2:])  #保留第三个维度开始\n",
    "            outputs.append(output)\n",
    "        if len(inputs) == 1:\n",
    "            return outputs[0]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def0f3bc",
   "metadata": {},
   "source": [
    "调整张量的维度 以适应模型的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47939123",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def div_batch_and_bboxes_dims(self, inputs):\n",
    "        \"\"\"\n",
    "        :param inputs:list of tensor\n",
    "        :return: list of tensor\n",
    "        \"\"\"\n",
    "        outputs = []\n",
    "        for input in inputs:\n",
    "            input_shape = input.get_shape().as_list()  #保存其形状信息\n",
    "            output = tf.reshape(input, [self.config.PER_GPU_IMAGE, -1,] + input_shape[1:])\n",
    "            outputs.append(output)\n",
    "        if len(inputs) == 1:\n",
    "            return outputs[0]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8d5b21",
   "metadata": {},
   "source": [
    "## 构建 Fast R-CNN 的训练目标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087e53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    @property\n",
    "    def build_frcnn_target(self):\n",
    "        '''\n",
    "        when training, we should know each reference box's label and gtbox,\n",
    "        in second stage\n",
    "        iou >= 0.5 is object\n",
    "        iou < 0.5 is background\n",
    "        this function need batch_slice\n",
    "        :return:\n",
    "        minibatch_reference_proboxes: (batch_szie, config.FAST_RCNN_MINIBATCH_SIZE, 4)[y1, x1, y2, x2]\n",
    "        minibatch_encode_gtboxes:(batch_szie, config.FAST_RCNN_MINIBATCH_SIZE, 4)[dy, dx, log(dh), log(dw)]\n",
    "        object_mask:(batch_szie, config.FAST_RCNN_MINIBATCH_SIZE) 1 indicate is object, 0 indicate is not objects\n",
    "        label_one_hot: (batch_szie, config.FAST_RCNN_MINIBATCH_SIZE, num_class)\n",
    "        '''\n",
    "        #输入真实的标注框的坐标和标签、RPN的建议框、配置参数\n",
    "        def batch_slice_build_target(gtboxes_and_label, rpn_proposals_boxes, config):\n",
    "\n",
    "            with tf.variable_scope('build_faster_rcnn_targets'):\n",
    "                \n",
    "                #对数据进行预处理操作 得到正负样本\n",
    "                with tf.variable_scope('fast_rcnn_find_positive_negative_samples'):\n",
    "                    #分离出边界框的坐标和对应的类别标签\n",
    "                    gtboxes = tf.cast(\n",
    "                        tf.reshape(gtboxes_and_label[:, :-1], [-1, 4]), tf.float32)\n",
    "                    gt_class_ids = tf.cast(\n",
    "                        tf.reshape(gtboxes_and_label[:, -1], [-1, ]), tf.int32)\n",
    "                    gtboxes, non_zeros = boxes_utils.trim_zeros_graph(gtboxes, name=\"trim_gt_box\")  # [M, 4]  #移除面积为0的框\n",
    "                    gt_class_ids = tf.boolean_mask(gt_class_ids, non_zeros)  #取出不为0的类别id\n",
    "                    rpn_proposals_boxes, _ = boxes_utils.trim_zeros_graph(rpn_proposals_boxes,  #对RPN预测框移除面积为0\n",
    "                                                                          name=\"trim_rpn_proposal_train\")\n",
    "\n",
    "                    ious = boxes_utils.iou_calculate(rpn_proposals_boxes, gtboxes)  # [N, M]  计算预测框和标签的iou值\n",
    "                    matchs = tf.cast(tf.argmax(ious, axis=1), tf.int32)  # [N, ]  得到 每个预测框对应标注框iou最大的值的索引\n",
    "                    max_iou_each_row = tf.reduce_max(ious, axis=1)  #得到每行的最大值\n",
    "                    #生成正样本 IOU高于0.5的\n",
    "                    positives = tf.cast(tf.greater_equal(max_iou_each_row, config.FAST_RCNN_IOU_POSITIVE_THRESHOLD), tf.int32)\n",
    "                    #根据索引match 提取标注框和类别                \n",
    "                    reference_boxes_mattached_gtboxes = tf.gather(gtboxes, matchs)  # [N, 4]\n",
    "                    gt_class_ids = tf.gather(gt_class_ids, matchs)  # [N, ]\n",
    "                    #将正样本转换成浮点型张量\n",
    "                    object_mask = tf.cast(positives, tf.float32)  # [N, ]\n",
    "                    # when box is background, not caculate gradient, so give a weight 0 to avoid caculate gradient\n",
    "                    gt_class_ids = gt_class_ids * positives\n",
    "                \n",
    "                #从正样本和负样本中选择一定数量的样本用于Fast-RCNN的训练\n",
    "                with tf.variable_scope('fast_rcnn_minibatch'):\n",
    "                    # choose the positive indices\n",
    "                    positive_indices = tf.reshape(tf.where(tf.not_equal(object_mask, 0.)), [-1])\n",
    "                    num_of_positives = tf.minimum(tf.shape(positive_indices)[0],\n",
    "                                                  tf.cast(config.FAST_RCNN_MINIBATCH_SIZE*config.FAST_RCNN_POSITIVE_RATE,\n",
    "                                                          tf.int32))\n",
    "                    positive_indices = tf.random_shuffle(positive_indices)\n",
    "                    positive_indices = tf.slice(positive_indices, begin=[0], size=[num_of_positives])\n",
    "                    # choose the negative indices,\n",
    "                    # Strictly propose the proportion of positive and negative is 1:3\n",
    "                    negative_indices = tf.reshape(tf.where(tf.equal(object_mask, 0.)), [-1])\n",
    "                    num_of_negatives = tf.cast(int(1. / config.FAST_RCNN_POSITIVE_RATE) * num_of_positives, tf.int32)\\\n",
    "                                       - num_of_positives\n",
    "\n",
    "                    num_of_negatives = tf.minimum(tf.shape(negative_indices)[0], num_of_negatives)\n",
    "                    negative_indices = tf.random_shuffle(negative_indices)\n",
    "                    negative_indices = tf.slice(negative_indices, begin=[0], size=[num_of_negatives])\n",
    "\n",
    "                    #将正样本索引和负样本索引按顺序合并成一个索引列表 minibatch_indices\n",
    "                    minibatch_indices = tf.concat([positive_indices, negative_indices], axis=0)\n",
    "                    \n",
    "                    #根据索引得到真实框和预测框\n",
    "                    minibatch_reference_gtboxes = tf.gather(reference_boxes_mattached_gtboxes,\n",
    "                                                            minibatch_indices)\n",
    "                    minibatch_reference_proboxes = tf.gather(rpn_proposals_boxes, minibatch_indices)\n",
    "                    # encode gtboxes\n",
    "                    minibatch_encode_gtboxes = \\\n",
    "                        encode_and_decode.encode_boxes(\n",
    "                            unencode_boxes=minibatch_reference_gtboxes,\n",
    "                            reference_boxes=minibatch_reference_proboxes,\n",
    "                            dev_factors=config.BBOX_STD_DEV)\n",
    "                    #根据索引得到物体掩码和类别\n",
    "                    object_mask = tf.gather(object_mask, minibatch_indices)\n",
    "                    gt_class_ids = tf.gather(gt_class_ids, minibatch_indices)\n",
    "\n",
    "                    # padding if necessary  根据参数提供的FAST_RCNN_MINIBATCH_SIZE，如果样本数不够 来补足样本\n",
    "                    gap = tf.cast(config.FAST_RCNN_MINIBATCH_SIZE - (num_of_positives + num_of_negatives), dtype=tf.int32)\n",
    "                    bbox_padding = tf.zeros((gap, 4))\n",
    "                    minibatch_reference_proboxes = tf.concat([minibatch_reference_proboxes, bbox_padding], axis=0)\n",
    "                    minibatch_encode_gtboxes = tf.concat([minibatch_encode_gtboxes, bbox_padding], axis=0)\n",
    "                    object_mask = tf.pad(object_mask, [(0, gap)])\n",
    "                    gt_class_ids = tf.pad(gt_class_ids, [(0, gap)])\n",
    "\n",
    "                return minibatch_reference_proboxes, minibatch_encode_gtboxes, object_mask, gt_class_ids\n",
    "\n",
    "            #将输入的标注框和候选框数据传递给每个 GPU，通过 batch_slice_build_target 函数构建 Fast R-CNN 的训练目标，\n",
    "            #得到每个 GPU 上的 mini-batch 训练数据，包括候选框、编码后的真实框、正负样本掩码和类别ID\n",
    "        minibatch_reference_proboxes, minibatch_encode_gtboxes, object_mask, gt_class_ids = \\\n",
    "                boxes_utils.batch_slice([self.gtboxes_and_label, self.rpn_proposals_boxes],\n",
    "                                        lambda x, y: batch_slice_build_target(x, y, self.config),\n",
    "                                        self.config.PER_GPU_IMAGE)\n",
    "        if DEBUG:\n",
    "            gt_vision = draw_boxes_with_categories(self.origin_image[0],\n",
    "                                                   self.gtboxes_and_label[0, :, :4],\n",
    "                                                   self.gtboxes_and_label[0, :, 4])\n",
    "            tf.summary.image(\"gt_vision\", gt_vision)\n",
    "\n",
    "            draw_bbox_train = draw_boxes_with_categories(self.origin_image[0],\n",
    "                                                         minibatch_reference_proboxes[0],\n",
    "                                                         gt_class_ids[0])\n",
    "            tf.summary.image(\"positive_proposal\", draw_bbox_train)\n",
    "\n",
    "        return minibatch_reference_proboxes, minibatch_encode_gtboxes, object_mask, gt_class_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff023466",
   "metadata": {},
   "source": [
    "为 Fast R-CNN 阶段的每个候选框分配一个级别，该级别将用于选择特征金字塔中相应级别的特征图来进行进一步的处理和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c656347",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def assign_level(self, minibatch_reference_proboxes):\n",
    "        \"\"\"\n",
    "        compute the level of rpn_proposals_boxes\n",
    "        :param: minibatch_reference_proboxes (batch_size, num_proposals, 4)[y1, x1, y2, x2]\n",
    "        return: (batch_size, num_proposals)\n",
    "        Note that we have not trim the elements padding is 0 which does not affect the finial result.\n",
    "        \"\"\"\n",
    "        with tf.name_scope('assign_levels'):\n",
    "            ymin, xmin, ymax, xmax = tf.unstack(minibatch_reference_proboxes, axis=2)\n",
    "\n",
    "            w = tf.maximum(xmax - xmin, 0.)  # avoid w is negative\n",
    "            h = tf.maximum(ymax - ymin, 0.)  # avoid h is negative\n",
    "\n",
    "            levels = tf.round(4. + tf.log(tf.sqrt(w*h + 1e-8)/224.0) / tf.log(2.))  # 4 + log_2(***)\n",
    "\n",
    "            levels = tf.maximum(levels, tf.ones_like(levels) * (np.float32(self.min_level)))  # level minimum is 2\n",
    "            levels = tf.minimum(levels, tf.ones_like(levels) * (np.float32(self.max_level)))  # level maximum is 5\n",
    "\n",
    "            return tf.cast(levels, tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c5a8d",
   "metadata": {},
   "source": [
    "### 从特征图中提取候选框的特征，并将这些特征整理为适合进入后续网络层处理的形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a6aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_rois(self, proposal_bbox):\n",
    "        '''\n",
    "        1)get roi from feature map\n",
    "        2)roi align or roi pooling. Here is roi align\n",
    "        :param: proposal_bbox: (batch_size, num_proposal, 4)[y1, x1, y2, x2]\n",
    "        :return:\n",
    "        all_level_rois: [batch_size, num_proposal, 7, 7, C]\n",
    "        '''\n",
    "        #首先调用aasign_level对预测框分配一个级别\n",
    "        levels = self.assign_level(proposal_bbox)\n",
    "\n",
    "        with tf.variable_scope('fast_rcnn_roi'):\n",
    "            pooled = []  #用于存储从不同级别的特征图中提取的候选框的特征\n",
    "            # this is aimed at reorder the pooling map (batch_size, num_proposal)\n",
    "            box_to_level = [] #存储每个候选框的索引以及其所属的级别信息\n",
    "            \n",
    "            for i in range(self.min_level, self.max_level + 1):\n",
    "                #根据级别取出索引和候选框\n",
    "                ix = tf.where(tf.equal(levels, i))\n",
    "                level_i_proposals = tf.gather_nd(proposal_bbox, ix)\n",
    "\n",
    "                # Box indicies for crop_and_resize.\n",
    "                box_indices = tf.cast(ix[:, 0], tf.int32) #候选框所属的批次索引\n",
    "\n",
    "                box_to_level.append(ix)\n",
    "\n",
    "                level_i_proposals = tf.stop_gradient(level_i_proposals)   #停止梯度计算 只计算特征\n",
    "                box_indices = tf.stop_gradient(box_indices)\n",
    "                \n",
    "                #根据目标尺寸大小创建图片张量\n",
    "                image_shape = tf.constant([self.config.TARGET_SIDE-1, self.config.TARGET_SIDE-1,\n",
    "                                           self.config.TARGET_SIDE-1, self.config.TARGET_SIDE-1], dtype=tf.float32)\n",
    "                #对候选框坐标进行归一化操作\n",
    "                normal_level_i_proposals = level_i_proposals / image_shape\n",
    "                \n",
    "                #从特征金字塔的不同层上提取与每个候选框相关的特征区域\n",
    "                level_i_cropped_rois = tf.image.crop_and_resize(self.feature_pyramid['P%d' % i],\n",
    "                                                                boxes=normal_level_i_proposals,\n",
    "                                                                box_ind=box_indices,\n",
    "                                                                crop_size=[self.config.ROI_SIZE, self.config.ROI_SIZE])\n",
    "                pooled.append(level_i_cropped_rois)\n",
    "\n",
    "            # Pack pooled features into one tensor 将不同的特征合并成一个张量\n",
    "            pooled = tf.concat(pooled, axis=0)\n",
    "            box_to_level = tf.concat(box_to_level, axis=0)\n",
    "            box_range = tf.expand_dims(tf.range(tf.shape(box_to_level)[0]), 1)  #添加一个维度表示索引范围的张量\n",
    "            box_to_level = tf.concat([tf.cast(box_to_level, tf.int32), box_range],  #将两个张量连接在一起\n",
    "                                     axis=1)\n",
    "            \n",
    "            #我们需要对池化后的特征进行重新排序，以便它们与原始框的顺序相匹配\n",
    "            # Rearrange pooled features to match the order of the original boxes\n",
    "            # Sort box_to_level by batch then box index\n",
    "            # TF doesn't have a way to sort by two columns, so merge them and sort.\n",
    "            sorting_tensor = box_to_level[:, 0] * 10000 + box_to_level[:, 1]\n",
    "            ix = tf.nn.top_k(sorting_tensor, k=tf.shape(\n",
    "                box_to_level)[0]).indices[::-1]\n",
    "            ix = tf.gather(box_to_level[:, 2], ix)\n",
    "            pooled = tf.gather(pooled, ix)\n",
    "            reshape_pooled = self.div_batch_and_bboxes_dims([pooled])\n",
    "            return reshape_pooled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1e697",
   "metadata": {},
   "source": [
    "### 通过提取特定区域的特征并计算类别距离，预测了每个提议框的类别分数和边界框编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00861738",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fast_rcnn_net(self, features, is_training):\n",
    "        \"\"\"\n",
    "        base the feature to compute the finial bbox and scores\n",
    "        :param reference_feature:(C-1, 7, 7,256) the feature of reference image\n",
    "        :param features:(batch_size, num_proposal, 7, 7, channels)\n",
    "        :return:\n",
    "        fast_rcnn_encode_boxes: (batch_size, num_proposal, num_classes*4)\n",
    "        fast_rcnn_scores:(batch_size, num_proposal, num_classes)\n",
    "        \"\"\"\n",
    "\n",
    "        def batch_slice_fast_rcnn_net(features, reference_feature, config, is_training):\n",
    "\n",
    "            #定义fast-rcnn网络作用域\n",
    "            with tf.variable_scope('fast_rcnn_net', reuse=tf.AUTO_REUSE):\n",
    "                #初始化全连接层 包括激活函数和权重初始化\n",
    "                with slim.arg_scope([slim.fully_connected],\n",
    "                                    activation_fn=None,\n",
    "                                    weights_initializer=tf.glorot_uniform_initializer(),\n",
    "                                    weights_regularizer=slim.l2_regularizer(config.WEIGHT_DECAY)):\n",
    "                    \n",
    "                    #归一化层的参数设置\n",
    "                    batch_norm_params = {\n",
    "                        'is_training': is_training,\n",
    "                        'decay': 0.997,\n",
    "                        'epsilon': 1e-5,\n",
    "                        'scale': True,\n",
    "                        'trainable': True,\n",
    "                        'updates_collections': tf.GraphKeys.UPDATE_OPS,\n",
    "                    }\n",
    "                    \n",
    "                    #定义卷积参数和作用域 包括激活函数 归一化和l2正则化衰减\n",
    "                    with slim.arg_scope([slim.conv2d],\n",
    "                                        stride=1,\n",
    "                                        padding=\"VALID\",\n",
    "                                        activation_fn=tf.nn.relu,\n",
    "                                        weights_initializer=tf.glorot_uniform_initializer(),\n",
    "                                        normalizer_fn=slim.batch_norm,\n",
    "                                        normalizer_params=batch_norm_params,\n",
    "                                        weights_regularizer=slim.l2_regularizer(config.WEIGHT_DECAY)):\n",
    "                        with slim.arg_scope([slim.batch_norm],\n",
    "                                            **batch_norm_params):\n",
    "\n",
    "                            #第一个卷积层\n",
    "                            bbox_net = slim.conv2d(inputs=features,\n",
    "                                                   num_outputs=1024,\n",
    "                                                   kernel_size=[self.config.ROI_SIZE, config.ROI_SIZE],\n",
    "                                                   scope=\"fc_1\")\n",
    "                            #第二个卷积层\n",
    "                            bbox_net = slim.conv2d(inputs=bbox_net,\n",
    "                                              num_outputs=1024,\n",
    "                                              kernel_size=[1, 1],\n",
    "                                              scope=\"fc_2\")\n",
    "                \n",
    "                #计算每个类别特征与参考特征之间的欧几里德距离的平方\n",
    "                class_features = tf.expand_dims(features, axis=1)\n",
    "                reference_feature = tf.expand_dims(reference_feature, axis=0)\n",
    "                class_net = tf.square(class_features - reference_feature)\n",
    "                \n",
    "                # 3D卷积层初始化\n",
    "                with slim.arg_scope([slim.conv3d],\n",
    "                                    stride=1,\n",
    "                                    padding=\"VALID\", #使用“VALID”填充策略，这意味着在不填充的情况下进行卷积操作，输出尺寸会随着卷积核尺寸和步幅而减小。\n",
    "                                    activation_fn=tf.nn.relu,\n",
    "                                    weights_initializer=tf.glorot_uniform_initializer(),\n",
    "                                    normalizer_fn=slim.batch_norm,\n",
    "                                    normalizer_params=batch_norm_params,\n",
    "                                    weights_regularizer=slim.l2_regularizer(config.WEIGHT_DECAY)):\n",
    "                    \n",
    "                    #3d卷积层用来计算特征之间的相关性\n",
    "                    class_net = slim.conv3d(inputs=class_net,\n",
    "                                            num_outputs=1,\n",
    "                                            kernel_size=[1, 7, 7],\n",
    "                                            scope=\"params_dist\")\n",
    "                # care about there is subtract when use weight, it don't need.\n",
    "                fast_rcnn_scores = tf.squeeze(class_net, axis=[2, 3, 4])  #维度2、3和4上尺寸为1的维度将被移除\n",
    "                # net = tf.squeeze(net, axis=[1, 2])\n",
    "                # fast_rcnn_scores = slim.fully_connected(net,\n",
    "                #                                         config.NUM_CLASS,\n",
    "                #                                         scope='classifier')\n",
    "                #通过全连接层进行预测，这一层的输出将包含类别数量乘以4（每个类别对应一个4维的边界框偏移量）的特征\n",
    "                fast_rcnn_encode_boxes = slim.fully_connected(bbox_net, config.NUM_CLASS * 4,  scope='regressor')\n",
    "\n",
    "                # 将全连接层的输出重新整形，使其变为一个形状为 [batch_size, num_classes, 4] 的张量。\n",
    "                #在这里，num_classes 表示类别数量，每个类别都对应一个包含4个偏移量的边界框编码。\n",
    "                fast_rcnn_encode_boxes = tf.reshape(fast_rcnn_encode_boxes, [-1, config.NUM_CLASS, 4])\n",
    "\n",
    "                return fast_rcnn_encode_boxes, fast_rcnn_scores\n",
    "        #对每个批次中的数据进行处理\n",
    "        fast_rcnn_encode_boxes, fast_rcnn_scores = boxes_utils.batch_slice([features],\n",
    "                                           lambda x: batch_slice_fast_rcnn_net(x, self.reference_feature,\n",
    "                                                                               self.config, is_training),\n",
    "                                           self.config.PER_GPU_IMAGE)\n",
    "\n",
    "        return fast_rcnn_encode_boxes, fast_rcnn_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa3be1a",
   "metadata": {},
   "source": [
    "### 计算fast_rcnn损失 \n",
    "包括分类损失(交叉熵损失）和位置损失(L1损失）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a140a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fast_rcnn_loss(self):\n",
    "    \n",
    "        #构建fast_rcnn训练目标 包括预测标签 真实标签 物体独热掩码 和 类别\n",
    "        minibatch_reference_proboxes, minibatch_encode_gtboxes,\\\n",
    "        object_mask, gt_class_ids = self.build_frcnn_target\n",
    "        \n",
    "        #获得预测框的池化特征\n",
    "        pooled_feature = self.get_rois(minibatch_reference_proboxes)\n",
    "        \n",
    "        #输入fast_rcnn网络 得到边界框和类别分数\n",
    "        fast_rcnn_predict_boxes, fast_rcnn_predict_scores = self.fast_rcnn_net(pooled_feature, self.IS_TRAINING)\n",
    "\n",
    "        #计算fast_rcnn loss\n",
    "        with tf.variable_scope(\"fast_rcnn_loss\"):\n",
    "            # trim zero graph\n",
    "            # minibatch_encode_gtboxes, non_zeros = boxes_utils.trim_zeros_graph(minibatch_encode_gtboxes,\n",
    "            #                                                                    name=\"trim_gtbox_finial_loss\")\n",
    "            # object_mask = tf.boolean_mask(object_mask, non_zeros)\n",
    "            # fast_rcnn_predict_boxes = tf.boolean_mask(fast_rcnn_predict_boxes, non_zeros)\n",
    "            # fast_rcnn_predict_boxes = tf.reshape(fast_rcnn_predict_boxes, [-1, self.config.NUM_CLASS, 4])\n",
    "            #\n",
    "            # fast_rcnn_predict_scores = tf.boolean_mask(fast_rcnn_predict_scores, non_zeros)\n",
    "            # label_one_hot = tf.boolean_mask(label_one_hot, non_zeros)\n",
    "\n",
    "            # from fast_rcnn_predict_boxes choose corresponding encode\n",
    "            row_index = tf.range(0, tf.shape(gt_class_ids)[1])\n",
    "            row_index = tf.expand_dims(row_index, 0)\n",
    "            multi_row_index = tf.tile(row_index, [self.config.PER_GPU_IMAGE, 1])\n",
    "            multi_row_index = tf.expand_dims(multi_row_index, axis=-1)\n",
    "            expand_gt_class_ids = tf.expand_dims(gt_class_ids, axis=-1)\n",
    "            index = tf.concat([multi_row_index, expand_gt_class_ids], axis=-1)\n",
    "            fast_rcnn_predict_boxes = boxes_utils.batch_slice([fast_rcnn_predict_boxes, index],\n",
    "                                                              lambda x, y: tf.gather_nd(x, y),\n",
    "                                                              self.config.PER_GPU_IMAGE)\n",
    "\n",
    "            # loss\n",
    "            with tf.variable_scope('fast_rcnn_classification_loss'):\n",
    "                fast_rcnn_classification_loss = tf.losses.sparse_softmax_cross_entropy(labels=gt_class_ids,\n",
    "                                                                                       logits=fast_rcnn_predict_scores)\n",
    "\n",
    "                fast_rcnn_classification_loss = tf.cond(tf.is_nan(fast_rcnn_classification_loss), lambda: 0.0,\n",
    "                                                        lambda: fast_rcnn_classification_loss)\n",
    "\n",
    "            with tf.variable_scope('fast_rcnn_location_loss'):\n",
    "                fast_rcnn_location_loss = losses.l1_smooth_losses(predict_boxes=fast_rcnn_predict_boxes,\n",
    "                                                                  gtboxes=minibatch_encode_gtboxes,\n",
    "                                                                  object_weights=object_mask)\n",
    "\n",
    "            return fast_rcnn_location_loss, fast_rcnn_classification_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c02c8e",
   "metadata": {},
   "source": [
    "### 对 Fast R-CNN 模型中的目标检测结果进行了一系列预处理和修剪操作，以获得最终的目标检测框的信息\n",
    "- 除去0\n",
    "- 解码预测框\n",
    "- 去除背景类别\n",
    "- 过滤低置信度的框\n",
    "- 进行非极大抑制操作 剔除重叠框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ea999",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fast_rcnn_proposals(self, rpn_proposal_bbox, encode_boxes, categories, scores, image_window):\n",
    "        \"\"\"\n",
    "        padding zeros to keep alignments\n",
    "        :return:\n",
    "        detection_boxes_scores_labels:(batch_size, config.MAX_DETECTION_INSTANCE, 6)\n",
    "        \"\"\"\n",
    "\n",
    "        def batch_slice_rcnn_proposals(rpn_proposal_bbox,\n",
    "                                       encode_boxes,\n",
    "                                       categories,\n",
    "                                       scores,\n",
    "                                       image_window,\n",
    "                                       config):\n",
    "            \"\"\"\n",
    "            mutilclass NMS\n",
    "            :param rpn_proposal_bbox: (N, 4)\n",
    "            :param encode_boxes: (N, 4)\n",
    "            :param categories:(N, )\n",
    "            :param scores: (N, )\n",
    "            :param image_window:(y1, x1, y2, x2) the boundary of image\n",
    "            :return:\n",
    "            detection_boxes_scores_labels : (-1, 6)[y1, x1, y2, x2, scores, labels]\n",
    "            \"\"\"\n",
    "            with tf.variable_scope('fast_rcnn_proposals'):\n",
    "                # trim the zero graph 除去面积为0的建议框\n",
    "                rpn_proposal_bbox, non_zeros = boxes_utils.trim_zeros_graph(rpn_proposal_bbox,\n",
    "                                                                            name=\"trim_proposals_detection\")\n",
    "                encode_boxes = tf.boolean_mask(encode_boxes, non_zeros)\n",
    "                categories = tf.boolean_mask(categories, non_zeros)\n",
    "                scores = tf.boolean_mask(scores, non_zeros)\n",
    "                \n",
    "                #预测框解码为实际边界框，并确保这些边界框不会超出图像边界的操作\n",
    "                fast_rcnn_decode_boxes = encode_and_decode.decode_boxes(encode_boxes=encode_boxes,\n",
    "                                                                        reference_boxes=rpn_proposal_bbox,\n",
    "                                                                        dev_factors=config.BBOX_STD_DEV)\n",
    "                fast_rcnn_decode_boxes = boxes_utils.clip_boxes_to_img_boundaries(fast_rcnn_decode_boxes,\n",
    "                                                                                  image_window)\n",
    "\n",
    "                # remove the background 移除背景类别\n",
    "                keep = tf.cast(tf.where(categories > 0)[:, 0], tf.int32)\n",
    "                if DEBUG:\n",
    "                    print_categories = tf.gather(categories, keep)\n",
    "                    print_scores = tf.gather(scores, keep)\n",
    "                    num_item = tf.minimum(tf.shape(print_scores)[0], 50)\n",
    "                    print_scores_vision, print_index = tf.nn.top_k(print_scores, k=num_item)\n",
    "                    print_categories_vision = tf.gather(print_categories, print_index)\n",
    "                    print_tensors(print_categories_vision, \"categories\")\n",
    "                    print_tensors(print_scores_vision, \"scores\")\n",
    "                    mean_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "                # Filter out low confidence boxes 过滤掉低置信度的预测框  和阈值config.FINAL_SCORE_THRESHOLD相比较\n",
    "                if config.FINAL_SCORE_THRESHOLD:\n",
    "                    conf_keep = tf.cast(tf.where(scores >= config.FINAL_SCORE_THRESHOLD)[:, 0], tf.int32)\n",
    "                    keep = tf.sets.set_intersection(tf.expand_dims(keep, 0),\n",
    "                                                    tf.expand_dims(conf_keep, 0))\n",
    "                    keep = tf.sparse_tensor_to_dense(keep)[0]\n",
    "\n",
    "                pre_nms_class_ids = tf.gather(categories, keep)\n",
    "                pre_nms_scores = tf.gather(scores, keep)\n",
    "                pre_nms_rois = tf.gather(fast_rcnn_decode_boxes, keep)\n",
    "                unique_pre_nms_class_ids = tf.unique(pre_nms_class_ids)[0]\n",
    "                \n",
    "                #基于类别的非最大抑制（NMS）操作，用于每个类别的检测框\n",
    "                def nms_keep_map(class_id):\n",
    "                    \"\"\"Apply Non-Maximum Suppression on ROIs of the given class.\"\"\"\n",
    "                    # Indices of ROIs of the given class\n",
    "                    ixs = tf.where(tf.equal(pre_nms_class_ids, class_id))[:, 0] #找到预NMS阶段中与给定类别 class_id 相等的检测框的索引\n",
    "                    # Apply NMS\n",
    "                    class_keep = tf.image.non_max_suppression(\n",
    "                        tf.gather(pre_nms_rois, ixs),\n",
    "                        tf.gather(pre_nms_scores, ixs),\n",
    "                        max_output_size=config.DETECTION_MAX_INSTANCES,\n",
    "                        iou_threshold=config.FAST_RCNN_NMS_IOU_THRESHOLD) #对给定类别的ROIs（Region of Interest）执行NMS操作，以剔除重叠的检测框\n",
    "                    # Map indicies\n",
    "                    class_keep = tf.gather(keep, tf.gather(ixs, class_keep))\n",
    "                    # Pad with -1 so returned tensors have the same shape\n",
    "                    gap = config.DETECTION_MAX_INSTANCES - tf.shape(class_keep)[0]\n",
    "                    class_keep = tf.pad(class_keep, [(0, gap)],\n",
    "                                        mode='CONSTANT', constant_values=-1)\n",
    "                    # Set shape so map_fn() can infer result shape\n",
    "                    class_keep.set_shape([config.DETECTION_MAX_INSTANCES])\n",
    "                    return class_keep\n",
    "                # 2. Map over class IDs\n",
    "                nms_keep = tf.map_fn(nms_keep_map, unique_pre_nms_class_ids,\n",
    "                                     dtype=tf.int32)\n",
    "                # 3. Merge results into one list, and remove -1 padding\n",
    "                nms_keep = tf.reshape(nms_keep, [-1])\n",
    "                nms_keep = tf.gather(nms_keep, tf.where(nms_keep > -1)[:, 0])\n",
    "                # 4. Compute intersection between keep and nms_keep 计算经过 NMS 和后续处理后的保留索引与原始 keep 索引的交集\n",
    "                keep = tf.sets.set_intersection(tf.expand_dims(keep, 0),\n",
    "                                                tf.expand_dims(nms_keep, 0))\n",
    "                keep = tf.sparse_tensor_to_dense(keep)[0]\n",
    "                # Keep top detections 选取最高分数的检测框\n",
    "                roi_count = config.DETECTION_MAX_INSTANCES\n",
    "                class_scores_keep = tf.gather(scores, keep)\n",
    "                num_keep = tf.minimum(tf.shape(class_scores_keep)[0], roi_count)\n",
    "                top_ids = tf.nn.top_k(class_scores_keep, k=num_keep, sorted=True)[1]\n",
    "                keep = tf.gather(keep, top_ids)\n",
    "\n",
    "                #这段代码将处理后的检测框坐标、类别标签和得分整合在一起，形成最终的检测结果，以便后续的输出和使用。\n",
    "                # Arrange output as [N, (y1, x1, y2, x2, class_id, score)]\n",
    "                # Coordinates are normalized.\n",
    "                detections = tf.concat([\n",
    "                    tf.gather(fast_rcnn_decode_boxes, keep),\n",
    "                    tf.to_float(tf.gather(categories, keep))[..., tf.newaxis],\n",
    "                    tf.gather(scores, keep)[..., tf.newaxis]\n",
    "                ], axis=1)\n",
    "                \n",
    "                #如果小于最大检测值，对检测数进行0填充 \n",
    "                # Pad with zeros if detections < DETECTION_MAX_INSTANCES\n",
    "                gap = config.DETECTION_MAX_INSTANCES - tf.shape(detections)[0]\n",
    "                detections = tf.pad(detections, [(0, gap), (0, 0)], \"CONSTANT\")\n",
    "\n",
    "                return detections\n",
    "        \n",
    "        #在每个gpu上进行批处理\n",
    "        detections = boxes_utils.batch_slice([rpn_proposal_bbox, encode_boxes, categories, scores, image_window],\n",
    "                                             lambda x, y, z, u, v: batch_slice_rcnn_proposals(x, y, z, u, v,\n",
    "                                             self.config), self.config.PER_GPU_IMAGE)\n",
    "        return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef55f73",
   "metadata": {},
   "source": [
    "### 对特征图进行目标检测 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b4351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fast_rcnn_detection(self):\n",
    "        \"\"\"\n",
    "        compute the predict bboxes, categories, categories\n",
    "        :return:\n",
    "        fast_rcnn_categories_bboxs:(batch_size, num_proposals, 4)\n",
    "        fast_rcnn_categories_scores:(batch_size, num_propsals)\n",
    "        fast_rcnn_categories:(batch_size, num_propsals)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # (batch_size, num_proposal, 7, 7, channels)\n",
    "        pooled_feature = self.get_rois(self.rpn_proposals_boxes)  #获得ROI池化特征\n",
    "        fast_rcnn_predict_boxes, fast_rcnn_predict_scores = self.fast_rcnn_net(pooled_feature, False) #预测框和分数\n",
    "\n",
    "        with tf.variable_scope(\"fast_rcnn_detection\"):\n",
    "            \n",
    "            #对预测分数进行softmax归一化操作\n",
    "            fast_rcnn_softmax_scores = slim.softmax(fast_rcnn_predict_scores)  # [-1, num_classes]\n",
    "\n",
    "            # gain the highest category and score and bounding box\n",
    "            fast_rcnn_categories = tf.argmax(fast_rcnn_softmax_scores, axis=2, output_type=tf.int32) # (N,)#得到每个样本每个类别中最大的\n",
    "            #创建行索引张量\n",
    "            row_index = tf.range(0, tf.shape(fast_rcnn_categories)[1])\n",
    "            row_index = tf.expand_dims(row_index, 0)\n",
    "            multi_row_index = tf.tile(row_index, [self.config.PER_GPU_IMAGE, 1])\n",
    "            multi_row_index = tf.expand_dims(multi_row_index, axis=-1)\n",
    "            expand_fast_rcnn_categories = tf.expand_dims(fast_rcnn_categories, axis=-1)\n",
    "            index = tf.concat([multi_row_index, expand_fast_rcnn_categories], axis=-1)\n",
    "            fast_rcnn_categories_bboxs = boxes_utils.batch_slice([fast_rcnn_predict_boxes, index],\n",
    "                                                                 lambda x, y: tf.gather_nd(x, y),\n",
    "                                                                 self.config.PER_GPU_IMAGE)\n",
    "            #得到每个ROI预测的最有可能的类别的概率\n",
    "            fast_rcnn_categories_scores = tf.reduce_max(fast_rcnn_softmax_scores, axis=2, keepdims=False)# (N,)\n",
    "            \n",
    "            #对预测框和类别分数进行处理\n",
    "            detections = self.fast_rcnn_proposals(self.rpn_proposals_boxes,\n",
    "                                                  fast_rcnn_categories_bboxs,\n",
    "                                                  fast_rcnn_categories,\n",
    "                                                  fast_rcnn_categories_scores,\n",
    "                                                  self.window)\n",
    "\n",
    "            return detections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
