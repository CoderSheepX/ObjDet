{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10af0dab",
   "metadata": {},
   "source": [
    "# train脚本 搭建比较检测器并进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109a92ef",
   "metadata": {},
   "source": [
    "### 设置训练参数 和 主干网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb19b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型的主要函数，处理训练、评估和预测三种模式\n",
    "def model_fn(features,\n",
    "             labels,\n",
    "             mode,\n",
    "             params,\n",
    "             config):\n",
    "\n",
    "    # ***********************************************************************************************\n",
    "    # *                                         share net                                           *\n",
    "    # ***********************************************************************************************\n",
    "    #参数解析\n",
    "    net_config = params[\"net_config\"]\n",
    "    #根据模式设置是否训练\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        IS_TRAINING = True\n",
    "    else:\n",
    "        IS_TRAINING = False\n",
    "    #获取原始图像的批次和大小\n",
    "    origin_image_batch = features[\"image\"]\n",
    "    image_window = features[\"image_window\"]\n",
    "    image_batch = origin_image_batch - net_config.PIXEL_MEANS  #将图像数据减去像素均值，以进行图像标准化（预处理）\n",
    "    # there is is_training means that bn is training, so it is important!\n",
    "    #获得主干网络res_net\n",
    "    _, share_net = get_network_byname(inputs=image_batch,\n",
    "                                      config=net_config,\n",
    "                                      is_training=False,\n",
    "                                      reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac4de6",
   "metadata": {},
   "source": [
    "### 搭建FPN金字塔池化网络 提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e6a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ***********************************************************************************************\n",
    "    # *                                            fpn                                              *\n",
    "    # ***********************************************************************************************\n",
    "    feature_pyramid = build_fpn.build_feature_pyramid(share_net, net_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7225ca",
   "metadata": {},
   "source": [
    "### 搭建RPN区域建议网络 将FPN的输出作为输入\n",
    "得到位置和分类（是否是物体）损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b437703d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1555849508.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    gtboxes_and_label_batch = labels.get(\"gt_box_labels\")\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "    # ***********************************************************************************************\n",
    "    # *                                            rpn                                              *\n",
    "    # ***********************************************************************************************\n",
    "    gtboxes_and_label_batch = labels.get(\"gt_box_labels\")\n",
    "    rpn = build_rpn.RPN(feature_pyramid=feature_pyramid,\n",
    "                        image_window=image_window,\n",
    "                        config=net_config)\n",
    "\n",
    "    # rpn_proposals_scores==(2000,)\n",
    "    rpn_proposals_boxes, rpn_proposals_scores = rpn.rpn_proposals(IS_TRAINING)\n",
    "    rpn_location_loss, rpn_classification_loss = rpn.rpn_losses(labels[\"minibatch_indices\"],\n",
    "                                                                labels[\"minibatch_encode_gtboxes\"],\n",
    "                                                                labels[\"minibatch_objects_one_hot\"])\n",
    "        \n",
    "    rpn_total_loss = rpn_classification_loss + rpn_location_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee9b195",
   "metadata": {},
   "source": [
    "### 提取参考图像的特征 为后续模型提供参考图像的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aedfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ***********************************************************************************************\n",
    "    # *                                        Rerference image                                    *   \n",
    "    # ***********************************************************************************************\n",
    "    #加载参考图像\n",
    "    reference_image = load_reference_image()\n",
    "    #转换类型\n",
    "    reference_image = tf.cast(reference_image, tf.float32)%%!\n",
    "    #将参考图像数据减去像素均值，以进行图像标准化\n",
    "    reference_image = reference_image - net_config.PIXEL_MEANS\n",
    "    #得到主干网络\n",
    "    _, reference_share_net = get_network_byname(inputs=reference_image,\n",
    "                                                config=net_config,\n",
    "                                                is_training=False,\n",
    "                                                reuse=tf.AUTO_REUSE)\n",
    "    #用FPN网络提取参考图像的特征\n",
    "    reference_feature_pyramid = build_fpn.build_feature_pyramid(reference_share_net, net_config)\n",
    "    # average the features of support images\n",
    "    # reference_feature_pyramid[key](C*S, H, W, 256)---->(C, 7, 7, 256)\n",
    "    with tf.variable_scope('reference_feature_origision'):\n",
    "        #对金字塔特征每个层级进行遍历 \n",
    "        for key, value in reference_feature_pyramid.items():\n",
    "            #用双线性插值将特征尺寸调整为ROI大小\n",
    "            reference_feature_pyramid[key] = tf.image.resize_bilinear(reference_feature_pyramid[key],\n",
    "                                                                      (net_config.ROI_SIZE, net_config.ROI_SIZE))\n",
    "            \n",
    "            #对特征图的第二维进行平均化\n",
    "            reference_feature_pyramid[key] = tf.reduce_mean(tf.reshape(reference_feature_pyramid[key],\n",
    "                                                            (net_config.NUM_CLASS-1, net_config.NUM_SUPPROTS,\n",
    "                                                             net_config.ROI_SIZE, net_config.ROI_SIZE,\n",
    "                                                             256)), axis=1)\n",
    "        #对特征金字塔的不同层级的特征进行平均，生成一个表示整个特征金字塔平均特征的张量\n",
    "        # average the features of fpn features\n",
    "        average_fpn_feature = []\n",
    "        for key, value in reference_feature_pyramid.items():\n",
    "            average_fpn_feature.append(value)\n",
    "        reference_fpn_features = tf.reduce_mean(tf.stack(average_fpn_feature, axis=0), axis=0)\n",
    "        \n",
    "        # compute the negative features\n",
    "        #构建参考图像的负特征 有助于增强模型的鲁棒性和泛化能力\n",
    "        with tf.variable_scope(\"reference_negative\"):\n",
    "            with slim.arg_scope([slim.conv2d],\n",
    "                                padding=\"SAME\",\n",
    "                                weights_initializer=tf.glorot_uniform_initializer(),\n",
    "                                weights_regularizer=slim.l2_regularizer(net_config.WEIGHT_DECAY)):\n",
    "                # the shape of positive features is (1, H, W, C*channels) 构建正特征\n",
    "                positive_features = tf.reshape(tf.transpose(reference_fpn_features, (1, 2, 0, 3)),\n",
    "                                    (1, net_config.ROI_SIZE, net_config.ROI_SIZE, (net_config.NUM_CLASS-1)*256))\n",
    "                # (1, H, W, channels) 对正特征进行卷积操作 得到负特征，并将其进行拼接\n",
    "                negative_feature = slim.conv2d(positive_features, num_outputs=256, kernel_size=[3,3], stride=1)\n",
    "                total_refernece_feature = tf.concat([negative_feature, reference_fpn_features], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b4ab1",
   "metadata": {},
   "source": [
    "### 构建Fast RCNN检测网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ba514",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ***********************************************************************************************\n",
    "    # *                                         Fast RCNN                                           *\n",
    "    # ***********************************************************************************************\n",
    "\n",
    "    #初始化fast_rcnn网络 将fpn和rpn的输出作为输入，同时传入真实标签\n",
    "    fast_rcnn = build_fast_rcnn.FastRCNN(feature_pyramid=feature_pyramid,\n",
    "                                         rpn_proposals_boxes=rpn_proposals_boxes,\n",
    "                                         origin_image=origin_image_batch,\n",
    "                                         gtboxes_and_label=gtboxes_and_label_batch,\n",
    "                                         reference_feature=total_refernece_feature,\n",
    "                                         config=net_config,\n",
    "                                         is_training=False,\n",
    "                                         image_window=image_window)\n",
    "    #进行检测 生成预测框 类别和分数\n",
    "    detections = fast_rcnn.fast_rcnn_detection()\n",
    "    if DEBUG:\n",
    "        rpn_proposals_vision = draw_boxes_with_scores(origin_image_batch[0, :, :, :],\n",
    "                                                      rpn_proposals_boxes[0, :50, :],\n",
    "                                                      rpn_proposals_scores[0, :50])\n",
    "        fast_rcnn_vision = draw_boxes_with_categories_and_scores(origin_image_batch[0, :, :, :],\n",
    "                                                                 detections[0, :, :4],\n",
    "                                                                 detections[0, :, 4],\n",
    "                                                                 detections[0, :, 5])\n",
    "        tf.summary.image(\"rpn_proposals_vision\", rpn_proposals_vision) \n",
    "        tf.summary.image(\"fast_rcnn_vision\", fast_rcnn_vision)\n",
    "\n",
    "    #计算fast_rcnn损失 包括分类损失和位置损失 总损失以权重系数为5进行拼接\n",
    "    fast_rcnn_location_loss, fast_rcnn_classification_loss = fast_rcnn.fast_rcnn_loss()\n",
    "    fast_rcnn_total_loss = 5.0*fast_rcnn_classification_loss + fast_rcnn_location_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b931bf6",
   "metadata": {},
   "source": [
    "### 训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e719930",
   "metadata": {},
   "outputs": [],
   "source": [
    "    EPOCH_BOUNDARY = [35, 50]\n",
    "    EPOCH = 60\n",
    "    WEIGHT_DECAY = 0.0001\n",
    "    EPSILON = 1e-5\n",
    "    MOMENTUM = 0.9\n",
    "    GPU_GROUPS = [\"/gpu:0\", \"/gpu:1\"]\n",
    "    LEARNING_RATE = 0.001\n",
    "    PER_GPU_IMAGE = 1\n",
    "    CLIP_GRADIENT_NORM = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "372ecc5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3705240355.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    with tf.variable_scope(\"regularization_losses\"):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "    with tf.variable_scope(\"regularization_losses\"):\n",
    "        #计算正则化损失\n",
    "        regularization_list = [tf.nn.l2_loss(w.read_value()) *\n",
    "                               net_config.WEIGHT_DECAY / tf.cast(tf.size(w.read_value()),\n",
    "                               tf.float32) for w in tf.trainable_variables() if 'gamma' not\n",
    "                               in w.name and 'beta' not in w.name]\n",
    "        regularization_losses = tf.add_n(regularization_list)\n",
    "    #模型的总损失 包括三部分\n",
    "    total_loss = regularization_losses + fast_rcnn_total_loss + rpn_total_loss\n",
    "    #跟踪学习过程中的step\n",
    "    global_step = slim.get_or_create_global_step()\n",
    "    #从检查点初始化模型\n",
    "    tf.train.init_from_checkpoint(net_config.CHECKPOINT_DIR, {net_config.NET_NAME + \"/\": net_config.NET_NAME + \"/\"})\n",
    "    \n",
    "    #模型优化过程\n",
    "    with tf.variable_scope(\"optimizer\"):\n",
    "        #创建分段常数学习率\n",
    "        lr = tf.train.piecewise_constant(global_step,\n",
    "                                         boundaries=[np.int64(net_config.BOUNDARY[0]), np.int64(net_config.BOUNDARY[1])],\n",
    "                                         values=[net_config.LEARNING_RATE, net_config.LEARNING_RATE / 10,\n",
    "                                                 net_config.LEARNING_RATE / 100])\n",
    "        #这里使用了 Momentum 优化器，它在梯度更新时不仅考虑当前梯度，还考虑了过去梯度的累积\n",
    "        optimizer = tf.train.MomentumOptimizer(lr, momentum=net_config.MOMENTUM)\n",
    "        #这是一个用于多 GPU 训练的优化器封装，它将原始优化器包装在内，以便处理多 GPU 训练中的梯度同步等问题\n",
    "        optimizer = tf.contrib.estimator.TowerOptimizer(optimizer)\n",
    "        #获取所有需要在训练过程中更新的操作，例如批归一化中的移动平均和方差更新。\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies([tf.group(*update_ops)]):\n",
    "            #计算总损失 total_loss 对于所有可训练变量的梯度。\n",
    "            grads = optimizer.compute_gradients(total_loss)\n",
    "            #使用梯度裁剪，限制梯度的范数不超过指定的阈值（这里是 5.0），以避免梯度爆炸的问题。\n",
    "            for i, (g, v) in enumerate(grads):\n",
    "                if g is not None:\n",
    "                    grads[i] = (tf.clip_by_norm(g, 5.0), v)  # clip gradients\n",
    "            #梯度更新\n",
    "            train_op = optimizer.apply_gradients(grads, global_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21031ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
