{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f6d6211",
   "metadata": {},
   "source": [
    "# 用来配置数据集、网络结构和训练的参数的脚本文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a685280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "\n",
    "class Config(object):\n",
    "\n",
    "    ##############################\n",
    "    # Data And Dataset\n",
    "    ##############################\n",
    "    CHECKPOINT_DIR= \"/root/userfolder/kuku/20180601_resnet_v2_imagenet_checkpoint\"\n",
    "    NUM_CLASS = 11 + 1\n",
    "    NUM_ITEM_DATASET = 5714\n",
    "    DATASET_NAME = 'tct'\n",
    "    DATA_DIR = \"./tfdata\"\n",
    "    MODLE_DIR = \"./logs\"\n",
    "    # resize and padding the image shape to (1024, 1024)\n",
    "    TARGET_SIDE = 1024\n",
    "    FAST_RCNN_MAX_INSTANCES = 100\n",
    "    PIXEL_MEANS = np.array([115.2, 118.8, 123.0])\n",
    "    NUM_SUPPROTS = 3\n",
    "\n",
    "    ###################################\n",
    "    # Network config\n",
    "    ###################################\n",
    "    # Anchor stride\n",
    "    # If 1 then anchors are created for each cell in the backbone feature map.\n",
    "    # If 2, then anchors are created for every other cell, and so on.\n",
    "    RPN_ANCHOR_STRIDE = 1\n",
    "    NET_NAME = 'resnet_model'\n",
    "    VERSION = 'v1_tct'\n",
    "    BASE_ANCHOR_SIZE_LIST = [32, 64, 128, 256, 512]\n",
    "    LEVEL = ['P2', 'P3', 'P4', 'P5', \"P6\"]\n",
    "    BACKBONE_STRIDES = [4, 8, 16, 32, 64]\n",
    "\n",
    "\n",
    "    ###################################\n",
    "    # Training Config\n",
    "    ###################################\n",
    "    EPOCH_BOUNDARY = [35, 50]\n",
    "    EPOCH = 60\n",
    "    WEIGHT_DECAY = 0.0001\n",
    "    EPSILON = 1e-5\n",
    "    MOMENTUM = 0.9\n",
    "    GPU_GROUPS = [\"/gpu:0\", \"/gpu:1\"]\n",
    "    LEARNING_RATE = 0.001\n",
    "    PER_GPU_IMAGE = 1\n",
    "    CLIP_GRADIENT_NORM = 5.0\n",
    "\n",
    "    ###################################\n",
    "    # RPN\n",
    "    ###################################\n",
    "    ANCHOR_RATIOS = [0.5, 1, 2]\n",
    "    RPN_NMS_IOU_THRESHOLD = 0.7\n",
    "    RPN_IOU_POSITIVE_THRESHOLD = 0.7\n",
    "    RPN_IOU_NEGATIVE_THRESHOLD = 0.3\n",
    "    RPN_MINIBATCH_SIZE = 256\n",
    "    RPN_POSITIVE_RATE = 0.5\n",
    "    RPN_TOP_K_NMS = 6000\n",
    "    MAX_PROPOSAL_NUM_TRAINING = 2000\n",
    "    MAX_PROPOSAL_NUM_INFERENCE = 1000\n",
    "    RPN_BBOX_STD_DEV = [0.1, 0.1, 0.25, 0.27]\n",
    "    BBOX_STD_DEV = [0.13, 0.13, 0.27, 0.26]\n",
    "\n",
    "    ###################################\n",
    "    # Fast_RCNN\n",
    "    ###################################\n",
    "    ROI_SIZE = 7\n",
    "    FAST_RCNN_NMS_IOU_THRESHOLD = 0.3\n",
    "    FINAL_SCORE_THRESHOLD = 0.7\n",
    "    FAST_RCNN_IOU_POSITIVE_THRESHOLD = 0.5\n",
    "    FAST_RCNN_MINIBATCH_SIZE = 200\n",
    "    FAST_RCNN_POSITIVE_RATE = 0.33\n",
    "    DETECTION_MAX_INSTANCES = 200\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.NUM_GPUS = len(self.GPU_GROUPS)\n",
    "        self.BATCH_SIZE = self.NUM_GPUS * self.PER_GPU_IMAGE\n",
    "        self.BOUNDARY =  [self.NUM_ITEM_DATASET * i // self.BATCH_SIZE for i in self.EPOCH_BOUNDARY] \n",
    "        self.SAVE_EVERY_N_STEP= int(self.NUM_ITEM_DATASET/self.BATCH_SIZE)\n",
    "        # (h ,w)\n",
    "        self.BACKBONE_SHAPES = np.array(\n",
    "            [[int(math.ceil(self.TARGET_SIDE / stride)),\n",
    "              int(math.ceil(self.TARGET_SIDE / stride))]\n",
    "             for stride in self.BACKBONE_STRIDES])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
